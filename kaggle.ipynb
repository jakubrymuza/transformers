{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_preparation import make_spec\n",
    "from models.Inception import InceptionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\rafci\\Desktop\\tensorflow-speech-recognition-challenge\\train\"\n",
    "test_dir = r\"C:\\Users\\rafci\\Desktop\\tensorflow-speech-recognition-challenge\\test\"\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    train_dir = r\"C:\\Users\\jakub\\Desktop\\PD\\sem10\\deep\\tensorflow-speech-recognition-challenge\\train\"\n",
    "    test_dir = r\"C:\\Users\\jakub\\Desktop\\PD\\sem10\\deep\\tensorflow-speech-recognition-challenge\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_test_list(test_dir):\n",
    "    test_list  = []\n",
    "     \n",
    "    files = os.listdir(os.path.join(test_dir,'audio'))\n",
    "    for _, f in enumerate(files):\n",
    "        test_list.append(f)\n",
    "\n",
    "    return test_list\n",
    "def create_test_set(file_list, test_dir):\n",
    "    X_array = np.zeros([len(file_list), 122, 85])\n",
    "    file_names = []\n",
    "    for ind, file in enumerate(file_list):\n",
    "        X_array[ind] = make_spec(file,test_dir)\n",
    "\n",
    "        file_names.append(file)\n",
    "    return X_array, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafci\\Desktop\\transformers\\data_preparation.py:46: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  D = librosa.amplitude_to_db(librosa.stft(sig[:FREQ], n_fft=512, hop_length=128, center=False),\n",
      "c:\\Users\\rafci\\Desktop\\transformers\\data_preparation.py:46: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  D = librosa.amplitude_to_db(librosa.stft(sig[:FREQ], n_fft=512, hop_length=128, center=False),\n"
     ]
    }
   ],
   "source": [
    "file_list = get_test_list(test_dir)\n",
    "X_test, test_file_names=create_test_set(file_list,test_dir)\n",
    "np.save(f\"data/X_test.npy\", np.expand_dims(X_test, -1)+1.3)\n",
    "np.savetxt(f\"data/test_file_names.txt\", test_file_names, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/X_test.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/X_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/X_test.npy'"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"data/X_test.npy\")\n",
    "X_test = X_test.reshape((-1, X_test.shape[1], X_test.shape[2]))\n",
    "print(X_test.shape)\n",
    "test_file_names = np.loadtxt('data/test_file_names.npy', dtype=str)\n",
    "print(test_file_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'bed',\n",
       " 1: 'bird',\n",
       " 2: 'cat',\n",
       " 3: 'dog',\n",
       " 4: 'down',\n",
       " 5: 'eight',\n",
       " 6: 'five',\n",
       " 7: 'four',\n",
       " 8: 'go',\n",
       " 9: 'happy',\n",
       " 10: 'house',\n",
       " 11: 'left',\n",
       " 12: 'marvin',\n",
       " 13: 'nine',\n",
       " 14: 'no',\n",
       " 15: 'off',\n",
       " 16: 'on',\n",
       " 17: 'one',\n",
       " 18: 'right',\n",
       " 19: 'seven',\n",
       " 20: 'sheila',\n",
       " 21: 'silence',\n",
       " 22: 'six',\n",
       " 23: 'stop',\n",
       " 24: 'three',\n",
       " 25: 'tree',\n",
       " 26: 'two',\n",
       " 27: 'up',\n",
       " 28: 'wow',\n",
       " 29: 'yes',\n",
       " 30: 'zero'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_dir+'/audio/')\n",
    "NB_CLASSES = len(classes)\n",
    "def convert_list_dict(lst):\n",
    "    res_dct = {i: val for i, val in enumerate(lst)}\n",
    "    return res_dct\n",
    "         \n",
    "classes_index = convert_list_dict(classes)\n",
    "print(type(classes_index))\n",
    "classes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, file_names):\n",
    "        self.X = X.float().transpose(2, 1).to('cuda')\n",
    "        self.file_names = file_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.file_names[idx]\n",
    "\n",
    "test_dataset = CustomDataset(X_test, test_file_names)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "INPUT_SHAPE = (85, 122)\n",
    "\n",
    "model = InceptionClassifier(INPUT_SHAPE, NB_CLASSES).to('cuda')\n",
    "model.load_state_dict(torch.load('saved_models/inception_aug.pth'))\n",
    "with open('outputs/output.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['fname', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, file_names in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for num,file_name in zip(predicted.cpu().numpy(),file_names):\n",
    "                predicted_word = classes_index[num]\n",
    "                \n",
    "                writer.writerow({'fname': file_name, 'label': predicted_word})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14, 23, 13, 18, 21,  0, 14, 23, 21, 22], device='cuda:0')\n",
      "['no', 'stop', 'nine', 'right', 'silence', 'bed', 'no', 'stop', 'silence', 'six']\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "words_list = [classes_index[num] for num in predicted.cpu().numpy()]\n",
    "print(words_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
