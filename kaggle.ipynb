{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "from models.Inception import InceptionClassifier\n",
    "train_dir = r\"C:\\Users\\rafci\\Desktop\\tensorflow-speech-recognition-challenge\\train\"\n",
    "test_dir = r\"C:\\Users\\rafci\\Desktop\\tensorflow-speech-recognition-challenge\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import make_spec,compute_fbank,wav_padding\n",
    "def get_test_list(test_dir):\n",
    "    test_list  = []\n",
    "     \n",
    "    files = os.listdir(os.path.join(test_dir,'audio'))\n",
    "    for i, f in enumerate(files):\n",
    "        # print(f)\n",
    "        # path = folder+'/'+f\n",
    "        test_list.append(f)\n",
    "\n",
    "    return test_list\n",
    "def create_test_set(file_list, test_dir, method = 'spec'):\n",
    "    if method=='spec':\n",
    "        X_array = np.zeros([len(file_list), 122, 85])\n",
    "    elif method=='fbank':\n",
    "        X_array = np.zeros([len(file_list), 97, 80])\n",
    "    file_names = []\n",
    "    for ind, file in enumerate(file_list):\n",
    "\n",
    "        if method == 'spec':\n",
    "            X_array[ind] = make_spec(file,test_dir)\n",
    "        elif method == 'fbank':\n",
    "            X_array[ind] = wav_padding(compute_fbank(test_dir+'/audio/'+file), 97, 80)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid case\")\n",
    "        # print(file,ind)\n",
    "        file_names.append(file)\n",
    "    return X_array, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158538, 122, 85)\n",
      "(158538,)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"data/X_test.npy\")\n",
    "X_test = X_test.reshape((-1, X_test.shape[1], X_test.shape[2]))\n",
    "print(X_test.shape)\n",
    "test_file_names = np.loadtxt('data/test_file_names.npy', dtype=str)\n",
    "print(test_file_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'bed',\n",
       " 1: 'bird',\n",
       " 2: 'cat',\n",
       " 3: 'dog',\n",
       " 4: 'down',\n",
       " 5: 'eight',\n",
       " 6: 'five',\n",
       " 7: 'four',\n",
       " 8: 'go',\n",
       " 9: 'happy',\n",
       " 10: 'house',\n",
       " 11: 'left',\n",
       " 12: 'marvin',\n",
       " 13: 'nine',\n",
       " 14: 'no',\n",
       " 15: 'off',\n",
       " 16: 'on',\n",
       " 17: 'one',\n",
       " 18: 'right',\n",
       " 19: 'seven',\n",
       " 20: 'sheila',\n",
       " 21: 'silence',\n",
       " 22: 'six',\n",
       " 23: 'stop',\n",
       " 24: 'three',\n",
       " 25: 'tree',\n",
       " 26: 'two',\n",
       " 27: 'up',\n",
       " 28: 'wow',\n",
       " 29: 'yes',\n",
       " 30: 'zero'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_dir+'/audio/')\n",
    "NB_CLASSES = len(classes)\n",
    "def convert_list_dict(lst):\n",
    "    res_dct = {i: val for i, val in enumerate(lst)}\n",
    "    return res_dct\n",
    "         \n",
    "classes_index = convert_list_dict(classes)\n",
    "print(type(classes_index))\n",
    "classes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, file_names):\n",
    "        self.X = X.float().transpose(2, 1).to('cuda')\n",
    "        self.file_names = file_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.file_names[idx]\n",
    "\n",
    "test_dataset = CustomDataset(X_test, test_file_names)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "INPUT_SHAPE = (85, 122)\n",
    "\n",
    "model = InceptionClassifier(INPUT_SHAPE, NB_CLASSES).to('cuda')\n",
    "model.load_state_dict(torch.load('saved_models/inception_aug.pth'))\n",
    "with open('outputs/output.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['fname', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, file_names in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for num,file_name in zip(predicted.cpu().numpy(),file_names):\n",
    "                predicted_word = classes_index[num]\n",
    "                \n",
    "                writer.writerow({'fname': file_name, 'label': predicted_word})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14, 23, 13, 18, 21,  0, 14, 23, 21, 22], device='cuda:0')\n",
      "['no', 'stop', 'nine', 'right', 'silence', 'bed', 'no', 'stop', 'silence', 'six']\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "words_list = [classes_index[num] for num in predicted.cpu().numpy()]\n",
    "print(words_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
